'''
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import joblib
import os

# æ–‡ä»¶è·¯å¾„
data_path = "data/workload_training_data.csv"

if not os.path.exists(data_path):
    print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®è®¤è·¯å¾„ä¸º data/workload_training_data.csv")
    exit(1)

# è¯»å–æ•°æ®
df = pd.read_csv(data_path)

# é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆå¯ä»¥æŒ‰éœ€è°ƒæ•´ï¼‰
features = ["cpu_percent", "write_bytes", "mem_percent"]
X = df[features]
y = df["workload_type"]

# è®­ç»ƒæ¨¡å‹
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X, y)

# ä¿å­˜æ¨¡å‹
model_path = "optimizer/workload_model.pkl"
joblib.dump(model, model_path)
print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå·²ä¿å­˜è‡³ {model_path}")
'''

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import LabelEncoder
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns

# æ–‡ä»¶è·¯å¾„
data_path = "data/workload_training_data.csv"

if not os.path.exists(data_path):
    print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®è®¤è·¯å¾„ä¸º data/workload_training_data.csv")
    exit(1)

df = pd.read_csv(data_path)

# è½¬æ¢å­—ç¬¦ä¸²åˆ—ï¼ˆå¦‚æœ‰ï¼‰
if 'tcp_congestion_control' in df.columns:
    le = LabelEncoder()
    df['tcp_congestion_encoded'] = le.fit_transform(df['tcp_congestion_control'])

# é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆæ›´å…¨é¢ï¼‰
features = [
    "cpu_percent", "load_avg_1", "load_avg_5", "load_avg_15",
    "gpu_util", "gpu_mem_used", "gpu_temp", "gpu_power",
    "mem_percent", "mem_used", "swap_used", "swap_percent",
    "read_bytes", "write_bytes", "bytes_sent", "bytes_recv"
]

if "tcp_congestion_encoded" in df.columns:
    features.append("tcp_congestion_encoded")

X = df[features]
y = df["workload_type"]

# æ•°æ®é›†åˆ’åˆ†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# æ¨¡å‹è®­ç»ƒ
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# æ¨¡å‹è¯„ä¼°
y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ æ¨¡å‹å‡†ç¡®ç‡ï¼š{acc:.4f}")

# æ··æ·†çŸ©é˜µæ˜¾ç¤ºä¸ä¿å­˜
cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.savefig("optimizer/model_confusion_matrix.png")
print("ğŸ“Š æ··æ·†çŸ©é˜µå·²ä¿å­˜ï¼šoptimizer/model_confusion_matrix.png")

# ç‰¹å¾é‡è¦æ€§å›¾
plt.figure(figsize=(10, 6))
importance = pd.Series(model.feature_importances_, index=features)
importance.sort_values().plot(kind='barh')
plt.title("Feature Importance")
plt.tight_layout()
plt.savefig("optimizer/feature_importance.png")
print("ğŸ“ˆ ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜ï¼šoptimizer/feature_importance.png")

# ä¿å­˜æ¨¡å‹
model_path = "optimizer/workload_model.pkl"
joblib.dump(model, model_path)
print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå·²ä¿å­˜è‡³ {model_path}")
