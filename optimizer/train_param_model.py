import pandas as pd
import os
import joblib
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_squared_error, r2_score

# === åŠ è½½æ•°æ® ===
data_path = "data/param_training_data.csv"
if not os.path.exists(data_path):
    print("âŒ æ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶ï¼š", data_path)
    exit(1)

df = pd.read_csv(data_path)

# === ç›®æ ‡å‚æ•°ï¼ˆè¦é¢„æµ‹çš„ç³»ç»Ÿå‚æ•°ï¼‰ ===
target_cols = [
    "kernel_sched_latency_ns",
    "kernel_sched_migration_cost_ns",
    "vm_swappiness",
    "vm_dirty_ratio",
    "vm_dirty_expire_centisecs",
    "tcp_rmem_min",
    "tcp_rmem_default",
    "tcp_rmem_max"
]

# === ç‰¹å¾åˆ—ï¼ˆç³»ç»ŸçŠ¶æ€ + è´Ÿè½½ç±»å‹ï¼‰===
feature_cols = [
    "cpu_percent", "load_avg_1", "load_avg_5", "load_avg_15",
    "gpu_util", "gpu_mem_used", "gpu_temp", "gpu_power",
    "mem_percent", "mem_used", "swap_used", "swap_percent",
    "read_bytes", "write_bytes", "bytes_sent", "bytes_recv",
    "tcp_congestion_encoded"
]

# åŠ å…¥ workload_typeï¼ˆOneHot ç¼–ç ï¼‰
feature_cols_full = feature_cols + ["workload_type"]

# åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
X_raw = df[feature_cols_full]
Y = df[target_cols]

# OneHot ç¼–ç  workload_type
preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), feature_cols),
        ("cat", OneHotEncoder(), ["workload_type"])
    ]
)

# ä½¿ç”¨å¤šè¾“å‡ºå›å½’æ¨¡å‹
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)))
])

# === æ‹†åˆ†è®­ç»ƒé›† & æµ‹è¯•é›† ===
X_train, X_test, y_train, y_test = train_test_split(X_raw, Y, test_size=0.2, random_state=42)

# === è®­ç»ƒæ¨¡å‹ ===
model.fit(X_train, y_train)
print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")

# === ä¿å­˜æ¨¡å‹ ===
joblib.dump(model, "optimizer/param_model.pkl")
print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º optimizer/param_model.pkl")

# === æ€§èƒ½è¯„ä¼° ===
y_pred = model.predict(X_test)

# è¯„ä¼°æ¯ä¸ªç›®æ ‡çš„è¯¯å·®
mse_scores = {}
r2_scores = {}
for i, col in enumerate(target_cols):
    mse = mean_squared_error(y_test[col], y_pred[:, i])
    r2 = r2_score(y_test[col], y_pred[:, i])
    mse_scores[col] = mse
    r2_scores[col] = r2
    print(f"ğŸ“Š {col} - MSE: {mse:.2f} | RÂ²: {r2:.3f}")

# å¯è§†åŒ– RÂ²
plt.figure(figsize=(10, 5))
plt.barh(target_cols, [r2_scores[c] for c in target_cols])
plt.xlabel("RÂ² Score")
plt.title("Model Prediction Accuracy (RÂ²)")
plt.tight_layout()
plt.savefig("optimizer/param_model_r2_scores.png")
print("ğŸ“ˆ RÂ² å¯è§†åŒ–å›¾å·²ä¿å­˜ä¸º optimizer/param_model_r2_scores.png")

